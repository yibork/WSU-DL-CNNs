{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta75FnTqz6_u"
   },
   "source": [
    "\n",
    "This notebook is used to test two different deep neural networks on one datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15588,
     "status": "ok",
     "timestamp": 1725568081134,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "vMt5Yw6Mc-Ol",
    "outputId": "d29fba3c-7042-4327-face-165007962319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (0.19.1+cu124)\n",
      "Requirement already satisfied: numpy in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: torch==2.4.1+cu124 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torchvision) (2.4.1+cu124)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch==2.4.1+cu124->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy->torch==2.4.1+cu124->torchvision) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "#install the necessary modules\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1725569880014,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "AMMntrpMzzom"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1725568122446,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "dcZdY0Hn34k2"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(), \n",
    "     transforms.RandomCrop(32, padding=4), \n",
    "     transforms.ToTensor(), \n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1725569969469,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "afwySqEp4N1O",
    "outputId": "d33f7b05-fde6-43fc-c8a8-648e470ee876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Data loaded successfully\n",
      "Validation set size:  1000\n",
      "Test set size:  9000\n",
      "Training set size:  50000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The Cifar dataset is divided into two main folders: one for training and one for testing. To further improve the model's evaluation, \n",
    "I will create a validation set by extracting 5% of the training data. \n",
    "This validation set will allow me to assess the model's accuracy during training without using the test set. \n",
    "By validating on data the model has never encountered, I can better determine if the model is overfitting, ensuring a more generalizable performance.\n",
    "        Validation set size: 1,000\n",
    "        Test set size: 9,000\n",
    "        Training set size: 50,000\n",
    "\"\"\"\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Function to split the dataset\n",
    "def dataset_split(test_dataset, val_ratio=0.1):\n",
    "    # Calculate validation size based on the ratio\n",
    "    val_size = int(len(test_dataset) * val_ratio)\n",
    "    train_size = len(test_dataset) - val_size\n",
    "    \n",
    "    test_dataset, val_dataset = random_split(test_dataset, [train_size, val_size])\n",
    "    \n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    return val_loader, test_loader\n",
    "\n",
    "val_loader, test_loader = dataset_split(test_dataset, val_ratio=0.1)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=False)\n",
    "print(\"Data loaded successfully\")\n",
    "print(\"Validation set size: \", len(val_loader.dataset))\n",
    "print(\"Test set size: \", len(test_loader.dataset))\n",
    "print(\"Training set size: \", len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (0.20.3)\n",
      "Requirement already satisfied: torch in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torchviz) (2.4.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->torchviz) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->torchviz) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->torchviz) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->torchviz) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->torchviz) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch->torchviz) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch->torchviz) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy->torch->torchviz) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1725572751512,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "KwvEkNuR2Lg0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cnn_model_architecture.dot'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Layer 1: Conv2d + BatchNorm + ReLU + MaxPool\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, padding=0),  # No padding\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Max pool (28x28 -> 14x14)\n",
    "        )\n",
    "        \n",
    "        # Layer 2: Conv2d + BatchNorm + ReLU + MaxPool\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=0),  # No padding\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Max pool (14x14 -> 6x6)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 512)  # Input size 64 * 6 * 6 = 2304\n",
    "        self.fc2 = nn.Linear(512, 10)  # Output size = 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply layer 1\n",
    "        x = self.layer1(x)\n",
    "        \n",
    "        # Apply layer 2\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61QQDe840QYv"
   },
   "source": [
    "[link text](https://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.6)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=100, eta_min=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, test_loader,num_epochs): \n",
    "    # To store training data for plotting\n",
    "    training_data = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'train_error': [],\n",
    "        'test_error': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        scheduler.step()\n",
    "        avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_error = 1 - (correct_train / total_train)\n",
    "\n",
    "        # Testing phase\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_test_loss += loss.item() * images.size(0)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_loader.dataset)\n",
    "        test_error = 1 - (correct_test / total_test)\n",
    "\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        # Store metrics\n",
    "        training_data['train_loss'].append(avg_train_loss)\n",
    "        training_data['test_loss'].append(avg_test_loss)\n",
    "        training_data['train_error'].append(train_error)\n",
    "        training_data['test_error'].append(test_error)\n",
    "        training_data['accuracy'].append(accuracy)\n",
    "        training_data['precision'].append(precision)\n",
    "        training_data['recall'].append(recall)\n",
    "        training_data['f1_score'].append(f1)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}, '\n",
    "              f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, '\n",
    "              f'Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    training_data['training_time'] = training_time\n",
    "\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_results(model, model_name, training_data):\n",
    "    torch.save(model.state_dict(), f'{model_name}_model.pth')\n",
    "    # Convert training data to a JSON-serializable format\n",
    "    serializable_data = {}\n",
    "    for key, value in training_data.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            serializable_data[key] = value.tolist()  # Convert Tensors to lists\n",
    "        elif isinstance(value, list) and isinstance(value[0], torch.Tensor):\n",
    "            serializable_data[key] = [v.tolist() for v in value]  # Convert lists of Tensors\n",
    "        else:\n",
    "            serializable_data[key] = value\n",
    "\n",
    "    # Save the training data as JSON\n",
    "    with open(f'{model_name}_training_data.json', 'w') as json_file:\n",
    "        json.dump(serializable_data, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model : CNNModel(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2304, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/100], Train Loss: 1.5783, Test Loss: 1.5627, Accuracy: 0.4609, Precision: 0.5100, Recall: 0.4609, F1 Score: 0.4340\n",
      "Epoch [2/100], Train Loss: 1.1827, Test Loss: 1.3597, Accuracy: 0.5416, Precision: 0.5706, Recall: 0.5416, F1 Score: 0.5246\n",
      "Epoch [3/100], Train Loss: 1.0316, Test Loss: 1.1944, Accuracy: 0.5919, Precision: 0.6293, Recall: 0.5919, F1 Score: 0.5811\n",
      "Epoch [4/100], Train Loss: 0.9402, Test Loss: 0.9704, Accuracy: 0.6643, Precision: 0.6729, Recall: 0.6643, F1 Score: 0.6596\n",
      "Epoch [5/100], Train Loss: 0.8829, Test Loss: 0.9639, Accuracy: 0.6739, Precision: 0.6857, Recall: 0.6739, F1 Score: 0.6713\n",
      "Epoch [6/100], Train Loss: 0.8356, Test Loss: 0.9837, Accuracy: 0.6659, Precision: 0.6744, Recall: 0.6659, F1 Score: 0.6599\n",
      "Epoch [7/100], Train Loss: 0.7950, Test Loss: 0.9434, Accuracy: 0.6860, Precision: 0.6970, Recall: 0.6860, F1 Score: 0.6845\n",
      "Epoch [8/100], Train Loss: 0.7641, Test Loss: 0.8543, Accuracy: 0.7089, Precision: 0.7127, Recall: 0.7089, F1 Score: 0.7061\n",
      "Epoch [9/100], Train Loss: 0.7407, Test Loss: 0.8492, Accuracy: 0.7063, Precision: 0.7229, Recall: 0.7063, F1 Score: 0.7097\n",
      "Epoch [10/100], Train Loss: 0.7098, Test Loss: 0.8100, Accuracy: 0.7218, Precision: 0.7296, Recall: 0.7218, F1 Score: 0.7231\n",
      "Epoch [11/100], Train Loss: 0.6880, Test Loss: 0.8635, Accuracy: 0.7069, Precision: 0.7307, Recall: 0.7069, F1 Score: 0.7092\n",
      "Epoch [12/100], Train Loss: 0.6740, Test Loss: 0.8040, Accuracy: 0.7241, Precision: 0.7359, Recall: 0.7241, F1 Score: 0.7245\n",
      "Epoch [13/100], Train Loss: 0.6540, Test Loss: 0.7715, Accuracy: 0.7403, Precision: 0.7484, Recall: 0.7403, F1 Score: 0.7402\n",
      "Epoch [14/100], Train Loss: 0.6366, Test Loss: 0.7536, Accuracy: 0.7484, Precision: 0.7582, Recall: 0.7484, F1 Score: 0.7497\n",
      "Epoch [15/100], Train Loss: 0.6204, Test Loss: 0.7696, Accuracy: 0.7460, Precision: 0.7536, Recall: 0.7460, F1 Score: 0.7464\n",
      "Epoch [16/100], Train Loss: 0.6021, Test Loss: 0.7459, Accuracy: 0.7506, Precision: 0.7579, Recall: 0.7506, F1 Score: 0.7512\n",
      "Epoch [17/100], Train Loss: 0.5887, Test Loss: 0.8074, Accuracy: 0.7359, Precision: 0.7611, Recall: 0.7359, F1 Score: 0.7390\n",
      "Epoch [18/100], Train Loss: 0.5803, Test Loss: 0.7525, Accuracy: 0.7547, Precision: 0.7620, Recall: 0.7547, F1 Score: 0.7561\n",
      "Epoch [19/100], Train Loss: 0.5672, Test Loss: 0.6783, Accuracy: 0.7770, Precision: 0.7768, Recall: 0.7770, F1 Score: 0.7760\n",
      "Epoch [20/100], Train Loss: 0.5518, Test Loss: 0.7355, Accuracy: 0.7601, Precision: 0.7700, Recall: 0.7601, F1 Score: 0.7605\n",
      "Epoch [21/100], Train Loss: 0.5430, Test Loss: 0.6998, Accuracy: 0.7636, Precision: 0.7692, Recall: 0.7636, F1 Score: 0.7651\n",
      "Epoch [22/100], Train Loss: 0.5301, Test Loss: 0.7115, Accuracy: 0.7630, Precision: 0.7681, Recall: 0.7630, F1 Score: 0.7630\n",
      "Epoch [23/100], Train Loss: 0.5211, Test Loss: 0.6984, Accuracy: 0.7648, Precision: 0.7706, Recall: 0.7648, F1 Score: 0.7647\n",
      "Epoch [24/100], Train Loss: 0.5148, Test Loss: 0.7050, Accuracy: 0.7697, Precision: 0.7787, Recall: 0.7697, F1 Score: 0.7708\n",
      "Epoch [25/100], Train Loss: 0.5054, Test Loss: 0.7280, Accuracy: 0.7640, Precision: 0.7763, Recall: 0.7640, F1 Score: 0.7645\n",
      "Epoch [26/100], Train Loss: 0.4914, Test Loss: 0.6786, Accuracy: 0.7810, Precision: 0.7850, Recall: 0.7810, F1 Score: 0.7810\n",
      "Epoch [27/100], Train Loss: 0.4802, Test Loss: 0.7291, Accuracy: 0.7641, Precision: 0.7783, Recall: 0.7641, F1 Score: 0.7662\n",
      "Epoch [28/100], Train Loss: 0.4719, Test Loss: 0.6664, Accuracy: 0.7807, Precision: 0.7839, Recall: 0.7807, F1 Score: 0.7805\n",
      "Epoch [29/100], Train Loss: 0.4639, Test Loss: 0.7141, Accuracy: 0.7711, Precision: 0.7784, Recall: 0.7711, F1 Score: 0.7707\n",
      "Epoch [30/100], Train Loss: 0.4581, Test Loss: 0.6976, Accuracy: 0.7762, Precision: 0.7797, Recall: 0.7762, F1 Score: 0.7762\n",
      "Epoch [31/100], Train Loss: 0.4421, Test Loss: 0.6904, Accuracy: 0.7852, Precision: 0.7876, Recall: 0.7852, F1 Score: 0.7857\n",
      "Epoch [32/100], Train Loss: 0.4456, Test Loss: 0.7020, Accuracy: 0.7820, Precision: 0.7862, Recall: 0.7820, F1 Score: 0.7824\n",
      "Epoch [33/100], Train Loss: 0.4362, Test Loss: 0.7069, Accuracy: 0.7776, Precision: 0.7839, Recall: 0.7776, F1 Score: 0.7776\n",
      "Epoch [34/100], Train Loss: 0.4215, Test Loss: 0.7040, Accuracy: 0.7807, Precision: 0.7887, Recall: 0.7807, F1 Score: 0.7814\n",
      "Epoch [35/100], Train Loss: 0.4174, Test Loss: 0.6689, Accuracy: 0.7859, Precision: 0.7872, Recall: 0.7859, F1 Score: 0.7852\n",
      "Epoch [36/100], Train Loss: 0.4068, Test Loss: 0.6758, Accuracy: 0.7858, Precision: 0.7872, Recall: 0.7858, F1 Score: 0.7859\n",
      "Epoch [37/100], Train Loss: 0.4055, Test Loss: 0.6698, Accuracy: 0.7922, Precision: 0.7936, Recall: 0.7922, F1 Score: 0.7917\n",
      "Epoch [38/100], Train Loss: 0.3927, Test Loss: 0.6793, Accuracy: 0.7877, Precision: 0.7939, Recall: 0.7877, F1 Score: 0.7890\n",
      "Epoch [39/100], Train Loss: 0.3824, Test Loss: 0.6721, Accuracy: 0.7921, Precision: 0.7926, Recall: 0.7921, F1 Score: 0.7915\n",
      "Epoch [40/100], Train Loss: 0.3770, Test Loss: 0.6630, Accuracy: 0.7840, Precision: 0.7880, Recall: 0.7840, F1 Score: 0.7847\n",
      "Epoch [41/100], Train Loss: 0.3747, Test Loss: 0.6637, Accuracy: 0.7921, Precision: 0.7951, Recall: 0.7921, F1 Score: 0.7928\n",
      "Epoch [42/100], Train Loss: 0.3633, Test Loss: 0.6630, Accuracy: 0.7904, Precision: 0.7915, Recall: 0.7904, F1 Score: 0.7902\n",
      "Epoch [43/100], Train Loss: 0.3597, Test Loss: 0.6971, Accuracy: 0.7902, Precision: 0.7948, Recall: 0.7902, F1 Score: 0.7908\n",
      "Epoch [44/100], Train Loss: 0.3519, Test Loss: 0.6674, Accuracy: 0.7926, Precision: 0.7962, Recall: 0.7926, F1 Score: 0.7934\n",
      "Epoch [45/100], Train Loss: 0.3415, Test Loss: 0.6699, Accuracy: 0.7962, Precision: 0.7988, Recall: 0.7962, F1 Score: 0.7967\n",
      "Epoch [46/100], Train Loss: 0.3377, Test Loss: 0.6700, Accuracy: 0.7969, Precision: 0.7971, Recall: 0.7969, F1 Score: 0.7964\n",
      "Epoch [47/100], Train Loss: 0.3377, Test Loss: 0.6668, Accuracy: 0.7962, Precision: 0.7985, Recall: 0.7962, F1 Score: 0.7966\n",
      "Epoch [48/100], Train Loss: 0.3280, Test Loss: 0.6689, Accuracy: 0.7998, Precision: 0.7998, Recall: 0.7998, F1 Score: 0.7992\n",
      "Epoch [49/100], Train Loss: 0.3206, Test Loss: 0.6856, Accuracy: 0.7913, Precision: 0.7953, Recall: 0.7913, F1 Score: 0.7909\n",
      "Epoch [50/100], Train Loss: 0.3154, Test Loss: 0.6612, Accuracy: 0.8002, Precision: 0.8034, Recall: 0.8002, F1 Score: 0.8009\n",
      "Epoch [51/100], Train Loss: 0.3119, Test Loss: 0.6637, Accuracy: 0.7983, Precision: 0.8011, Recall: 0.7983, F1 Score: 0.7990\n",
      "Epoch [52/100], Train Loss: 0.3023, Test Loss: 0.6661, Accuracy: 0.7978, Precision: 0.7984, Recall: 0.7978, F1 Score: 0.7976\n",
      "Epoch [53/100], Train Loss: 0.3028, Test Loss: 0.6544, Accuracy: 0.8038, Precision: 0.8058, Recall: 0.8038, F1 Score: 0.8039\n",
      "Epoch [54/100], Train Loss: 0.2944, Test Loss: 0.6929, Accuracy: 0.7936, Precision: 0.7974, Recall: 0.7936, F1 Score: 0.7943\n",
      "Epoch [55/100], Train Loss: 0.2887, Test Loss: 0.6608, Accuracy: 0.8051, Precision: 0.8064, Recall: 0.8051, F1 Score: 0.8051\n",
      "Epoch [56/100], Train Loss: 0.2819, Test Loss: 0.6893, Accuracy: 0.7987, Precision: 0.7996, Recall: 0.7987, F1 Score: 0.7982\n",
      "Epoch [57/100], Train Loss: 0.2762, Test Loss: 0.6809, Accuracy: 0.8018, Precision: 0.8036, Recall: 0.8018, F1 Score: 0.8022\n",
      "Epoch [58/100], Train Loss: 0.2686, Test Loss: 0.6540, Accuracy: 0.8047, Precision: 0.8049, Recall: 0.8047, F1 Score: 0.8043\n",
      "Epoch [59/100], Train Loss: 0.2678, Test Loss: 0.6652, Accuracy: 0.8087, Precision: 0.8087, Recall: 0.8087, F1 Score: 0.8082\n",
      "Epoch [60/100], Train Loss: 0.2618, Test Loss: 0.6621, Accuracy: 0.8048, Precision: 0.8066, Recall: 0.8048, F1 Score: 0.8050\n",
      "Epoch [61/100], Train Loss: 0.2553, Test Loss: 0.6820, Accuracy: 0.8053, Precision: 0.8070, Recall: 0.8053, F1 Score: 0.8055\n",
      "Epoch [62/100], Train Loss: 0.2492, Test Loss: 0.6826, Accuracy: 0.8048, Precision: 0.8060, Recall: 0.8048, F1 Score: 0.8042\n",
      "Epoch [63/100], Train Loss: 0.2443, Test Loss: 0.6630, Accuracy: 0.8123, Precision: 0.8123, Recall: 0.8123, F1 Score: 0.8118\n",
      "Epoch [64/100], Train Loss: 0.2404, Test Loss: 0.6856, Accuracy: 0.8021, Precision: 0.8021, Recall: 0.8021, F1 Score: 0.8014\n",
      "Epoch [65/100], Train Loss: 0.2345, Test Loss: 0.6706, Accuracy: 0.8099, Precision: 0.8107, Recall: 0.8099, F1 Score: 0.8096\n",
      "Epoch [66/100], Train Loss: 0.2330, Test Loss: 0.6651, Accuracy: 0.8120, Precision: 0.8114, Recall: 0.8120, F1 Score: 0.8115\n",
      "Epoch [67/100], Train Loss: 0.2288, Test Loss: 0.6932, Accuracy: 0.8096, Precision: 0.8105, Recall: 0.8096, F1 Score: 0.8093\n",
      "Epoch [68/100], Train Loss: 0.2239, Test Loss: 0.6679, Accuracy: 0.8166, Precision: 0.8163, Recall: 0.8166, F1 Score: 0.8162\n",
      "Epoch [69/100], Train Loss: 0.2198, Test Loss: 0.6517, Accuracy: 0.8181, Precision: 0.8181, Recall: 0.8181, F1 Score: 0.8175\n",
      "Epoch [70/100], Train Loss: 0.2147, Test Loss: 0.6747, Accuracy: 0.8133, Precision: 0.8128, Recall: 0.8133, F1 Score: 0.8126\n",
      "Epoch [71/100], Train Loss: 0.2126, Test Loss: 0.6689, Accuracy: 0.8143, Precision: 0.8147, Recall: 0.8143, F1 Score: 0.8143\n",
      "Epoch [72/100], Train Loss: 0.2051, Test Loss: 0.6704, Accuracy: 0.8158, Precision: 0.8167, Recall: 0.8158, F1 Score: 0.8156\n",
      "Epoch [73/100], Train Loss: 0.2036, Test Loss: 0.6817, Accuracy: 0.8134, Precision: 0.8132, Recall: 0.8134, F1 Score: 0.8126\n",
      "Epoch [74/100], Train Loss: 0.2004, Test Loss: 0.6675, Accuracy: 0.8122, Precision: 0.8122, Recall: 0.8122, F1 Score: 0.8119\n",
      "Epoch [75/100], Train Loss: 0.1957, Test Loss: 0.6606, Accuracy: 0.8139, Precision: 0.8134, Recall: 0.8139, F1 Score: 0.8134\n",
      "Epoch [76/100], Train Loss: 0.1943, Test Loss: 0.6818, Accuracy: 0.8140, Precision: 0.8152, Recall: 0.8140, F1 Score: 0.8141\n",
      "Epoch [77/100], Train Loss: 0.1918, Test Loss: 0.6494, Accuracy: 0.8194, Precision: 0.8202, Recall: 0.8194, F1 Score: 0.8196\n",
      "Epoch [78/100], Train Loss: 0.1868, Test Loss: 0.6877, Accuracy: 0.8152, Precision: 0.8163, Recall: 0.8152, F1 Score: 0.8153\n",
      "Epoch [79/100], Train Loss: 0.1864, Test Loss: 0.6687, Accuracy: 0.8153, Precision: 0.8155, Recall: 0.8153, F1 Score: 0.8151\n",
      "Epoch [80/100], Train Loss: 0.1822, Test Loss: 0.6845, Accuracy: 0.8176, Precision: 0.8185, Recall: 0.8176, F1 Score: 0.8176\n",
      "Epoch [81/100], Train Loss: 0.1795, Test Loss: 0.6898, Accuracy: 0.8174, Precision: 0.8173, Recall: 0.8174, F1 Score: 0.8171\n",
      "Epoch [82/100], Train Loss: 0.1788, Test Loss: 0.6647, Accuracy: 0.8190, Precision: 0.8197, Recall: 0.8190, F1 Score: 0.8190\n",
      "Epoch [83/100], Train Loss: 0.1732, Test Loss: 0.6775, Accuracy: 0.8150, Precision: 0.8154, Recall: 0.8150, F1 Score: 0.8150\n",
      "Epoch [84/100], Train Loss: 0.1719, Test Loss: 0.6911, Accuracy: 0.8140, Precision: 0.8145, Recall: 0.8140, F1 Score: 0.8139\n",
      "Epoch [85/100], Train Loss: 0.1738, Test Loss: 0.6763, Accuracy: 0.8161, Precision: 0.8170, Recall: 0.8161, F1 Score: 0.8163\n",
      "Epoch [86/100], Train Loss: 0.1687, Test Loss: 0.6701, Accuracy: 0.8177, Precision: 0.8177, Recall: 0.8177, F1 Score: 0.8176\n",
      "Epoch [87/100], Train Loss: 0.1636, Test Loss: 0.6846, Accuracy: 0.8153, Precision: 0.8165, Recall: 0.8153, F1 Score: 0.8157\n",
      "Epoch [88/100], Train Loss: 0.1669, Test Loss: 0.6978, Accuracy: 0.8164, Precision: 0.8169, Recall: 0.8164, F1 Score: 0.8166\n",
      "Epoch [89/100], Train Loss: 0.1677, Test Loss: 0.6780, Accuracy: 0.8176, Precision: 0.8164, Recall: 0.8176, F1 Score: 0.8168\n",
      "Epoch [90/100], Train Loss: 0.1644, Test Loss: 0.6819, Accuracy: 0.8162, Precision: 0.8161, Recall: 0.8162, F1 Score: 0.8159\n",
      "Epoch [91/100], Train Loss: 0.1617, Test Loss: 0.6804, Accuracy: 0.8174, Precision: 0.8172, Recall: 0.8174, F1 Score: 0.8172\n",
      "Epoch [92/100], Train Loss: 0.1632, Test Loss: 0.6714, Accuracy: 0.8233, Precision: 0.8236, Recall: 0.8233, F1 Score: 0.8233\n",
      "Epoch [93/100], Train Loss: 0.1610, Test Loss: 0.7023, Accuracy: 0.8202, Precision: 0.8215, Recall: 0.8202, F1 Score: 0.8206\n",
      "Epoch [94/100], Train Loss: 0.1595, Test Loss: 0.6796, Accuracy: 0.8194, Precision: 0.8192, Recall: 0.8194, F1 Score: 0.8191\n",
      "Epoch [95/100], Train Loss: 0.1598, Test Loss: 0.7000, Accuracy: 0.8142, Precision: 0.8146, Recall: 0.8142, F1 Score: 0.8143\n",
      "Epoch [96/100], Train Loss: 0.1598, Test Loss: 0.6709, Accuracy: 0.8224, Precision: 0.8220, Recall: 0.8224, F1 Score: 0.8220\n",
      "Epoch [97/100], Train Loss: 0.1570, Test Loss: 0.6893, Accuracy: 0.8124, Precision: 0.8125, Recall: 0.8124, F1 Score: 0.8122\n",
      "Epoch [98/100], Train Loss: 0.1593, Test Loss: 0.7044, Accuracy: 0.8172, Precision: 0.8173, Recall: 0.8172, F1 Score: 0.8171\n",
      "Epoch [99/100], Train Loss: 0.1571, Test Loss: 0.6806, Accuracy: 0.8196, Precision: 0.8194, Recall: 0.8196, F1 Score: 0.8193\n",
      "Epoch [100/100], Train Loss: 0.1552, Test Loss: 0.6854, Accuracy: 0.8209, Precision: 0.8207, Recall: 0.8209, F1 Score: 0.8205\n"
     ]
    }
   ],
   "source": [
    "print(f'Training model : {model}')\n",
    "training_data = train_and_evaluate(model, train_loader, test_loader, num_epochs=100)\n",
    "\n",
    "save_model_and_results(model, f'DCNN', training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Network on the whole validation set: 81.70%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# Loop through both models to evaluate them on the whole validation set\n",
    "accuracy = evaluate_model(model, val_loader)\n",
    "print(f'Accuracy for Network on the whole validation set: {accuracy:.2%}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNIDTvxa7B1irZDHIQLXrAb",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

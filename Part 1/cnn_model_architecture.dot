digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2802056448176 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	2802056508272 [label=AddmmBackward0]
	2802056510768 -> 2802056508272
	2802053806976 [label="fc2.bias
 (10)" fillcolor=lightblue]
	2802053806976 -> 2802056510768
	2802056510768 [label=AccumulateGrad]
	2802056510864 -> 2802056508272
	2802056510864 [label=ReluBackward0]
	2802056508464 -> 2802056510864
	2802056508464 [label=AddmmBackward0]
	2802056510624 -> 2802056508464
	2802056447456 [label="fc1.bias
 (512)" fillcolor=lightblue]
	2802056447456 -> 2802056510624
	2802056510624 [label=AccumulateGrad]
	2802056510672 -> 2802056508464
	2802056510672 [label=ViewBackward0]
	2802056508992 -> 2802056510672
	2802056508992 [label=MaxPool2DWithIndicesBackward0]
	2802056509232 -> 2802056508992
	2802056509232 [label=ReluBackward0]
	2802056509328 -> 2802056509232
	2802056509328 [label=NativeBatchNormBackward0]
	2802056509424 -> 2802056509328
	2802056509424 [label=ConvolutionBackward0]
	2802056509616 -> 2802056509424
	2802056509616 [label=MaxPool2DWithIndicesBackward0]
	2802056509808 -> 2802056509616
	2802056509808 [label=ReluBackward0]
	2802056509712 -> 2802056509808
	2802056509712 [label=NativeBatchNormBackward0]
	2802055889680 -> 2802056509712
	2802055889680 [label=ConvolutionBackward0]
	2802055889248 -> 2802055889680
	2802053849952 [label="layer1.0.weight
 (32, 3, 5, 5)" fillcolor=lightblue]
	2802053849952 -> 2802055889248
	2802055889248 [label=AccumulateGrad]
	2802055889632 -> 2802055889680
	2802056446016 [label="layer1.0.bias
 (32)" fillcolor=lightblue]
	2802056446016 -> 2802055889632
	2802055889632 [label=AccumulateGrad]
	2802055889488 -> 2802056509712
	2802056446096 [label="layer1.1.weight
 (32)" fillcolor=lightblue]
	2802056446096 -> 2802055889488
	2802055889488 [label=AccumulateGrad]
	2802055888960 -> 2802056509712
	2802056446176 [label="layer1.1.bias
 (32)" fillcolor=lightblue]
	2802056446176 -> 2802055888960
	2802055888960 [label=AccumulateGrad]
	2802056509568 -> 2802056509424
	2802056446576 [label="layer2.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2802056446576 -> 2802056509568
	2802056509568 [label=AccumulateGrad]
	2802056509520 -> 2802056509424
	2802056446736 [label="layer2.0.bias
 (64)" fillcolor=lightblue]
	2802056446736 -> 2802056509520
	2802056509520 [label=AccumulateGrad]
	2802056509376 -> 2802056509328
	2802056446816 [label="layer2.1.weight
 (64)" fillcolor=lightblue]
	2802056446816 -> 2802056509376
	2802056509376 [label=AccumulateGrad]
	2802056509136 -> 2802056509328
	2802056446976 [label="layer2.1.bias
 (64)" fillcolor=lightblue]
	2802056446976 -> 2802056509136
	2802056509136 [label=AccumulateGrad]
	2802056508560 -> 2802056508464
	2802056508560 [label=TBackward0]
	2802056509280 -> 2802056508560
	2802056447376 [label="fc1.weight
 (512, 2304)" fillcolor=lightblue]
	2802056447376 -> 2802056509280
	2802056509280 [label=AccumulateGrad]
	2802056510816 -> 2802056508272
	2802056510816 [label=TBackward0]
	2802056509184 -> 2802056510816
	2802053805296 [label="fc2.weight
 (10, 512)" fillcolor=lightblue]
	2802053805296 -> 2802056509184
	2802056509184 [label=AccumulateGrad]
	2802056508272 -> 2802056448176
}
